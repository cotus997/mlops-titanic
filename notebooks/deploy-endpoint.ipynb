{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment, Workspace\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "preproc_train=pd.read_csv('../data/train/preproc.csv')\n",
        "preproc_train.drop(columns='Unnamed: 0',inplace=True)\n",
        "preproc_train.columns\n",
        "X = preproc_train.drop(\"Survived\",axis=1)\n",
        "y = preproc_train[\"Survived\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "ws= Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.model import Model as AMLModel\n",
        "def get_model(\n",
        "    model_name: str,\n",
        "    model_version: int = None,  # If none, return latest model\n",
        "    tag_name: str = None,\n",
        "    tag_value: str = None,\n",
        "    aml_workspace: Workspace = None\n",
        ") -> AMLModel:\n",
        "    \"\"\"\n",
        "    Retrieves and returns a model from the workspace by its name\n",
        "    and (optional) tag.\n",
        "\n",
        "    Parameters:\n",
        "    aml_workspace (Workspace): aml.core Workspace that the model lives.\n",
        "    model_name (str): name of the model we are looking for\n",
        "    (optional) model_version (str): model version. Latest if not provided.\n",
        "    (optional) tag (str): the tag value & name the model was registered under.\n",
        "\n",
        "    Return:\n",
        "    A single aml model from the workspace that matches the name and tag, or\n",
        "    None.\n",
        "    \"\"\"\n",
        "    if aml_workspace is None:\n",
        "        print(\"No workspace defined - using current experiment workspace.\")\n",
        "        raise ValueError(\n",
        "                \"No workspace provided\"\n",
        "            )\n",
        "\n",
        "    tags = None\n",
        "    if tag_name is not None or tag_value is not None:\n",
        "        # Both a name and value must be specified to use tags.\n",
        "        if tag_name is None or tag_value is None:\n",
        "            raise ValueError(\n",
        "                \"model_tag_name and model_tag_value should both be supplied\"\n",
        "                + \"or excluded\"  # NOQA: E501\n",
        "            )\n",
        "        tags = [[tag_name, tag_value]]\n",
        "\n",
        "    model = None\n",
        "    if model_version is not None:\n",
        "        # TODO(tcare): Finding a specific version currently expects exceptions\n",
        "        # to propagate in the case we can't find the model. This call may\n",
        "        # result in a WebserviceException that may or may not be due to the\n",
        "        # model not existing.\n",
        "        model = AMLModel(\n",
        "            aml_workspace,\n",
        "            name=model_name,\n",
        "            version=model_version,\n",
        "            tags=tags)\n",
        "    else:\n",
        "        models = AMLModel.list(\n",
        "            aml_workspace, name=model_name, tags=tags, latest=True)\n",
        "        if len(models) == 1:\n",
        "            model = models[0]\n",
        "        elif len(models) > 1:\n",
        "            raise Exception(\"Expected only one model\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "ml_client= MLClient.from_config(DefaultAzureCredential())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=get_model(\"titanic-xgb.pkl\",aml_workspace=ws)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "environment = Environment('my-sklearn-environment')\n",
        "environment.python.conda_dependencies = CondaDependencies.create(conda_packages=[\n",
        "    'pip==20.2.4'],\n",
        "    pip_packages=[\n",
        "    'azureml-defaults',\n",
        "    'inference-schema[numpy-support]',\n",
        "    'joblib',\n",
        "    'numpy',\n",
        "    \n",
        "    'xgboost',\n",
        "    'scikit-learn=={}'.format(sklearn.__version__)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(workspace=Workspace.create(name='mlops-aml-ws', subscription_id='f90533aa-280d-40b9-9949-a7ba0ee9511f', resource_group='mlops-rg'), name=titanic-xgb.pkl, id=titanic-xgb.pkl:5, version=5, tags={'area': 'Titanic_classification', 'run_id': '1f9fdd03-05d1-4508-92f9-237fea39c39d', 'experiment_name': 'evaluation', 'azureml.nodeid': '3d62ba08', 'azureml.pipeline': '1f9fdd03-05d1-4508-92f9-237fea39c39d', 'mlflow.source.type': 'JOB', 'mlflow.source.name': 'train.py', 'dataset_id': '84aecbe0-f2bb-4815-b21c-21bb22ffec6d', 'mlflow.parentRunId': '1f9fdd03-05d1-4508-92f9-237fea39c39d', 'mlflow.rootRunId': '1f9fdd03-05d1-4508-92f9-237fea39c39d', 'mlflow.runName': 'magenta_beach_wm03kcg4', 'mlflow.user': 'Giosuè Cotugno', 'mse': '0.02242152466367713'}, properties={})"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import os\n",
        "#os.chdir('Users/giosue.cotugno/mlops_titanic/notebooks/')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model deploying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1671188657183
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core import Model\n",
        "\n",
        "\n",
        "service_name = 'titanic1endpoint'\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='../src/scoring/score.py', environment=environment)\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name=service_name,\n",
        "                       models=[model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AciWebservice(workspace=Workspace.create(name='mlops-aml-ws', subscription_id='f90533aa-280d-40b9-9949-a7ba0ee9511f', resource_group='mlops-rg'), name=titanic1endpoint, image_id=None, image_digest=None, compute_type=ACI, state=Failed, scoring_uri=None, tags=None, properties={'azureml.git.repository_uri': 'git@github.com:cotus997/mlops-titanic.git', 'mlflow.source.git.repoURL': 'git@github.com:cotus997/mlops-titanic.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'c2e076d2a23cea4735b3947b6066024bdd239d57', 'mlflow.source.git.commit': 'c2e076d2a23cea4735b3947b6066024bdd239d57', 'azureml.git.dirty': 'True'}, created_by={'userObjectId': '0ede9b9c-2b54-4172-a26d-bbeff841eda9', 'userPuId': '10037FFEA30E4C08', 'userIdp': None, 'userAltSecId': None, 'userIss': 'https://sts.windows.net/e99647dc-1b08-454a-bf8c-699181b389ab/', 'userTenantId': 'e99647dc-1b08-454a-bf8c-699181b389ab', 'userName': 'Giosuè Cotugno', 'upn': 'giosue.cotugno@studio.unibo.it'})"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy\n",
        "\n",
        "input_payload = json.dumps({\n",
        "    'data': X[0:2].tolist(),\n",
        "    'method': 'predict_proba'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
        "})\n",
        "\n",
        "output = service.run(input_payload)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi model endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1=get_model(\"titanic-xgb.pkl\",aml_workspace=ws,model_version=7)\n",
        "model_2=get_model(\"my-sklearn-model\",aml_workspace=ws,model_version=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aci_service_name = \"aciservice-multimodel\"\n",
        "inference_config = InferenceConfig(entry_script=\"../src/scoring/score_multi.py\", environment=environment)\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(ws, aci_service_name, [model_1, model_2], inference_config, deployment_config, overwrite=True)\n",
        "service.wait_for_deployment(True)\n",
        "\n",
        "print(service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.get_logs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test web service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "test_sample = json.dumps({'data': X[0:2].tolist()})\n",
        "\n",
        "prediction = service.run(test_sample)\n",
        "\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy to AKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.compute import AksCompute, ComputeTarget\n",
        "from azureml.core.webservice import Webservice, AksWebservice"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## New environment for monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "environment_monitoring = Environment('inference-env-monitoring')\n",
        "environment_monitoring.python.conda_dependencies = CondaDependencies.create(conda_packages=[\n",
        "    'pip==20.2.4'],\n",
        "    pip_packages=[\n",
        "    'azureml-defaults',\n",
        "    'inference-schema[numpy-support]',\n",
        "    'joblib',\n",
        "    'numpy',\n",
        "    'azureml-monitoring',\n",
        "    'xgboost',\n",
        "    'scikit-learn=={}'.format(sklearn.__version__)\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inference config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "inference_config = InferenceConfig(entry_script='../src/scoring/score_monitoring.py', environment=environment_monitoring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        " # Use the default configuration (can also provide parameters to customize)\n",
        "prov_config = AksCompute.provisioning_configuration()\n",
        "\n",
        "# Create the cluster\n",
        "aks_target = ComputeTarget.create(workspace = ws, \n",
        "                                    name = 'akscluster1', \n",
        "                                    provisioning_configuration = prov_config)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Provision the AKS Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing cluster, use it.\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your AKS cluster\n",
        "aks_name = 'akscompute1' \n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # config:\n",
        "    '''\n",
        "    \"parameters\": {\n",
        "    \"location\": {\n",
        "      \"value\": \"westeurope\"\n",
        "    },\n",
        "    \"workspaceName\": {\n",
        "      \"value\": \"mlops-AML-WS\"\n",
        "    },\n",
        "    \"computeInstanceName\": {\n",
        "      \"value\": \"akscompute1\"\n",
        "    },\n",
        "    \"agentCount\": {\n",
        "      \"value\": 3\n",
        "    },\n",
        "    \"agentVMSize\": {\n",
        "      \"value\": \"Standard_A2_v2\"\n",
        "    },\n",
        "    \"clusterPurpose\": {\n",
        "      \"value\": \"DevTest\"\n",
        "    }\n",
        "  }\n",
        "    '''\n",
        "    # Use the default configuration (can also provide parameters to customize)\n",
        "    prov_config = AksCompute.provisioning_configuration()\n",
        "    \n",
        "    # Create the cluster\n",
        "    aks_target = ComputeTarget.create(workspace = ws, \n",
        "                                    name = aks_name, \n",
        "                                    provisioning_configuration = prov_config)\n",
        "\n",
        "if aks_target.get_status() != \"Succeeded\":\n",
        "    aks_target.wait_for_completion(show_output=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy model on AKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=get_model('titanic-xgb.pkl',aml_workspace=ws,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_11864/1709174487.py:4: FutureWarning: azureml.core.model:\n",
            "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
            "please refer to respective documentations \n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoint-sdk-v2 /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
            "For more information on migration, see https://aka.ms/acimoemigration. \n",
            "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
            "  aks_service = Model.deploy(workspace=ws,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-12-16 16:38:43+00:00 Creating Container Registry if not exists.\n",
            "2022-12-16 16:38:43+00:00 Registering the environment.\n",
            "2022-12-16 16:38:44+00:00 Building image..\n",
            "2022-12-16 16:49:01+00:00 Creating resources in AKS.\n",
            "2022-12-16 16:49:02+00:00 Submitting deployment to compute.\n",
            "2022-12-16 16:49:02+00:00 Checking the status of deployment aks-service-1..\n",
            "2022-12-16 16:52:05+00:00 Checking the status of inference endpoint aks-service-1.\n",
            "Succeeded\n",
            "AKS service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n"
          ]
        }
      ],
      "source": [
        "aks_config = AksWebservice.deploy_configuration(collect_model_data=True, enable_app_insights=True)\n",
        "aks_service_name ='aks-service-1'\n",
        "\n",
        "aks_service = Model.deploy(workspace=ws,\n",
        "                           name=aks_service_name,\n",
        "                           models=[model],\n",
        "                           inference_config=inference_config,\n",
        "                           deployment_config=aks_config,\n",
        "                           deployment_target=aks_target)\n",
        "\n",
        "aks_service.wait_for_deployment(show_output = True)\n",
        "print(aks_service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "test_sample = json.dumps({'data':[ [0.0,0.0,3.0,25.14,0.0,0.0,8.4583]]})\n",
        "\n",
        "prediction = aks_service.run(test_sample)\n",
        "\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "aks_service.delete()\n",
        "aks_target.delete()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
