{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "    os.chdir('Users/giosue.cotugno/mlops_titanic/notebooks/')\n",
        "except:\n",
        "    print('already moved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment, Workspace\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "import sklearn\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "preproc_train=pd.read_csv('../data/train/preproc.csv')\n",
        "preproc_train.drop(columns='Unnamed: 0',inplace=True)\n",
        "preproc_train.columns\n",
        "X = preproc_train.drop(\"Survived\",axis=1)\n",
        "y = preproc_train[\"Survived\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "ws= Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.model import Model as AMLModel\n",
        "def get_model(\n",
        "    model_name: str,\n",
        "    model_version: int = None,  # If none, return latest model\n",
        "    tag_name: str = None,\n",
        "    tag_value: str = None,\n",
        "    aml_workspace: Workspace = None\n",
        ") -> AMLModel:\n",
        "    \"\"\"\n",
        "    Retrieves and returns a model from the workspace by its name\n",
        "    and (optional) tag.\n",
        "\n",
        "    Parameters:\n",
        "    aml_workspace (Workspace): aml.core Workspace that the model lives.\n",
        "    model_name (str): name of the model we are looking for\n",
        "    (optional) model_version (str): model version. Latest if not provided.\n",
        "    (optional) tag (str): the tag value & name the model was registered under.\n",
        "\n",
        "    Return:\n",
        "    A single aml model from the workspace that matches the name and tag, or\n",
        "    None.\n",
        "    \"\"\"\n",
        "    if aml_workspace is None:\n",
        "        print(\"No workspace defined - using current experiment workspace.\")\n",
        "        raise ValueError(\n",
        "                \"No workspace provided\"\n",
        "            )\n",
        "\n",
        "    tags = None\n",
        "    if tag_name is not None or tag_value is not None:\n",
        "        # Both a name and value must be specified to use tags.\n",
        "        if tag_name is None or tag_value is None:\n",
        "            raise ValueError(\n",
        "                \"model_tag_name and model_tag_value should both be supplied\"\n",
        "                + \"or excluded\"  # NOQA: E501\n",
        "            )\n",
        "        tags = [[tag_name, tag_value]]\n",
        "\n",
        "    model = None\n",
        "    if model_version is not None:\n",
        "        # TODO(tcare): Finding a specific version currently expects exceptions\n",
        "        # to propagate in the case we can't find the model. This call may\n",
        "        # result in a WebserviceException that may or may not be due to the\n",
        "        # model not existing.\n",
        "        model = AMLModel(\n",
        "            aml_workspace,\n",
        "            name=model_name,\n",
        "            version=model_version,\n",
        "            tags=tags)\n",
        "    else:\n",
        "        models = AMLModel.list(\n",
        "            aml_workspace, name=model_name, tags=tags, latest=True)\n",
        "        if len(models) == 1:\n",
        "            model = models[0]\n",
        "        elif len(models) > 1:\n",
        "            raise Exception(\"Expected only one model\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "ml_client= MLClient.from_config(DefaultAzureCredential())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=get_model(\"titanic-xgb.pkl\",aml_workspace=ws)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "environment = Environment('my-sklearn-environment')\n",
        "environment.python.conda_dependencies = CondaDependencies.create(conda_packages=[\n",
        "    'pip==20.2.4'],\n",
        "    pip_packages=[\n",
        "    'azureml-defaults',\n",
        "    'inference-schema[numpy-support]',\n",
        "    'joblib',\n",
        "    'numpy',\n",
        "    'azureml_core',\n",
        "    'xgboost',\n",
        "    'scikit-learn=={}'.format(sklearn.__version__)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(workspace=Workspace.create(name='mlops-aml-ws', subscription_id='f90533aa-280d-40b9-9949-a7ba0ee9511f', resource_group='mlops-rg'), name=titanic-xgb.pkl, id=titanic-xgb.pkl:5, version=5, tags={'area': 'Titanic_classification', 'run_id': '1f9fdd03-05d1-4508-92f9-237fea39c39d', 'experiment_name': 'evaluation', 'azureml.nodeid': '3d62ba08', 'azureml.pipeline': '1f9fdd03-05d1-4508-92f9-237fea39c39d', 'mlflow.source.type': 'JOB', 'mlflow.source.name': 'train.py', 'dataset_id': '84aecbe0-f2bb-4815-b21c-21bb22ffec6d', 'mlflow.parentRunId': '1f9fdd03-05d1-4508-92f9-237fea39c39d', 'mlflow.rootRunId': '1f9fdd03-05d1-4508-92f9-237fea39c39d', 'mlflow.runName': 'magenta_beach_wm03kcg4', 'mlflow.user': 'Giosuè Cotugno', 'mse': '0.02242152466367713'}, properties={})"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import os\n",
        "#os.chdir('Users/giosue.cotugno/mlops_titanic/notebooks/')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model deploying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1671188657183
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "service_name = 'titanic1endpoint'\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='../src/scoring/score.py', environment=environment)\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name=service_name,\n",
        "                       models=[model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AciWebservice(workspace=Workspace.create(name='mlops-aml-ws', subscription_id='f90533aa-280d-40b9-9949-a7ba0ee9511f', resource_group='mlops-rg'), name=titanic1endpoint, image_id=None, image_digest=None, compute_type=ACI, state=Failed, scoring_uri=None, tags=None, properties={'azureml.git.repository_uri': 'git@github.com:cotus997/mlops-titanic.git', 'mlflow.source.git.repoURL': 'git@github.com:cotus997/mlops-titanic.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'c2e076d2a23cea4735b3947b6066024bdd239d57', 'mlflow.source.git.commit': 'c2e076d2a23cea4735b3947b6066024bdd239d57', 'azureml.git.dirty': 'True'}, created_by={'userObjectId': '0ede9b9c-2b54-4172-a26d-bbeff841eda9', 'userPuId': '10037FFEA30E4C08', 'userIdp': None, 'userAltSecId': None, 'userIss': 'https://sts.windows.net/e99647dc-1b08-454a-bf8c-699181b389ab/', 'userTenantId': 'e99647dc-1b08-454a-bf8c-699181b389ab', 'userName': 'Giosuè Cotugno', 'upn': 'giosue.cotugno@studio.unibo.it'})"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy\n",
        "\n",
        "input_payload = json.dumps({\n",
        "    'data': X[0:2].tolist(),\n",
        "    'method': 'predict_proba'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
        "})\n",
        "\n",
        "output = service.run(input_payload)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi model endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1=get_model(\"titanic-xgb.pkl\",aml_workspace=ws,model_version=7)\n",
        "model_2=get_model(\"my-sklearn-model\",aml_workspace=ws,model_version=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9815/2624093246.py:7: FutureWarning: azureml.core.model:\n",
            "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
            "please refer to respective documentations \n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoint-sdk-v2 /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
            "For more information on migration, see https://aka.ms/acimoemigration. \n",
            "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
            "  service = Model.deploy(ws, aci_service_name, [model_1, model_2], inference_config, deployment_config, overwrite=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-12-19 17:05:04+00:00 Creating Container Registry if not exists.\n",
            "2022-12-19 17:05:04+00:00 Registering the environment.\n",
            "2022-12-19 17:05:05+00:00 Use the existing image.\n",
            "2022-12-19 17:05:05+00:00 Generating deployment configuration.\n",
            "2022-12-19 17:05:06+00:00 Submitting deployment to compute.\n",
            "2022-12-19 17:05:09+00:00 Checking the status of deployment aciservice-multimodel..\n",
            "2022-12-19 17:07:53+00:00 Checking the status of inference endpoint aciservice-multimodel.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aci_service_name = \"aciservice-multimodel\"\n",
        "inference_config = InferenceConfig(entry_script=\"../src/scoring/score_multi.py\", environment=environment)\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(ws, aci_service_name, [model_1, model_2], inference_config, deployment_config, overwrite=True)\n",
        "service.wait_for_deployment(True)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test web service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "ename": "ConnectionError",
          "evalue": "HTTPConnectionPool(host='b4dab246-dddf-4d76-a066-265a3de89d38.westeurope.azurecontainer.io', port=80): Max retries exceeded with url: /score (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4e58ff9190>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/socket.py:918\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    917\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 918\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    919\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[1;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1255\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1255\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1301\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1250\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1250\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1010\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1010\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1012\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m \n\u001b[1;32m   1014\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:950\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_conn(conn)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f4e58ff9190>: Failed to establish a new connection: [Errno -2] Name or service not known",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    783\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 785\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    786\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    787\u001b[0m )\n\u001b[1;32m    788\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='b4dab246-dddf-4d76-a066-265a3de89d38.westeurope.azurecontainer.io', port=80): Max retries exceeded with url: /score (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4e58ff9190>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/deploy-endpoint.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/deploy-endpoint.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/deploy-endpoint.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m test_sample \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps({\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m: [[\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m3.0\u001b[39m,\u001b[39m25.14\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m8.4583\u001b[39m],[\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m3.0\u001b[39m,\u001b[39m25.14\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m8.4583\u001b[39m]]})\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/deploy-endpoint.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m prediction \u001b[39m=\u001b[39m service\u001b[39m.\u001b[39;49mrun(test_sample)\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/deploy-endpoint.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(prediction)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/aci.py:388\u001b[0m, in \u001b[0;36mAciWebservice.run\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring_uri:\n\u001b[1;32m    383\u001b[0m     \u001b[39mraise\u001b[39;00m WebserviceException(\u001b[39m'\u001b[39m\u001b[39mError attempting to call webservice, scoring_uri unavailable. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    384\u001b[0m                               \u001b[39m'\u001b[39m\u001b[39mThis could be due to a failed deployment, or the service is not ready yet.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    385\u001b[0m                               \u001b[39m'\u001b[39m\u001b[39mCurrent State: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    386\u001b[0m                               \u001b[39m'\u001b[39m\u001b[39mErrors: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror), logger\u001b[39m=\u001b[39mmodule_logger)\n\u001b[0;32m--> 388\u001b[0m resp \u001b[39m=\u001b[39m ClientBase\u001b[39m.\u001b[39;49m_execute_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_webservice_session\u001b[39m.\u001b[39;49mpost, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring_uri, data\u001b[39m=\u001b[39;49minput_data)\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauth_enabled:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/clientbase.py:374\u001b[0m, in \u001b[0;36mClientBase._execute_func\u001b[0;34m(cls, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_func\u001b[39m(\u001b[39mcls\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    373\u001b[0m     \u001b[39m# reset the backoff from 32 seconds to 1 second\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_func_internal(\n\u001b[1;32m    375\u001b[0m         DEFAULT_SHORT_BACKOFF, DEFAULT_RETRIES, module_logger, func, _noop_reset, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/clientbase.py:367\u001b[0m, in \u001b[0;36mClientBase._execute_func_internal\u001b[0;34m(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n\u001b[1;32m    366\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m--> 367\u001b[0m     left_retry \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_retry(back_off, left_retry, total_retry, error, logger, func)\n\u001b[1;32m    369\u001b[0m reset_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/clientbase.py:399\u001b[0m, in \u001b[0;36mClientBase._handle_retry\u001b[0;34m(cls, back_off, left_retry, total_retry, error, logger, func)\u001b[0m\n\u001b[1;32m    397\u001b[0m status_code \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[39mif\u001b[39;00m left_retry \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m    400\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, HttpOperationError) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(error, HTTPError):\n\u001b[1;32m    401\u001b[0m     status_code \u001b[39m=\u001b[39m error\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/clientbase.py:358\u001b[0m, in \u001b[0;36mClientBase._execute_func_internal\u001b[0;34m(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mClientBase: Calling \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m with url \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(func_name, func_url))\n\u001b[0;32m--> 358\u001b[0m     response \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    359\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(response, Response) \u001b[39mand\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_is_retryable_status_code(response\u001b[39m.\u001b[39mstatus_code)\n\u001b[1;32m    360\u001b[0m             \u001b[39mand\u001b[39;00m left_retry \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m    361\u001b[0m         \u001b[39m# This is the handle the error case 1. response.raise_for_status only throws HTTPError exception.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m         \u001b[39m# if the status_code is retryable and it is not the last retry, then the exception is thrown.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m         \u001b[39m# Otherwise, we will return the response directly.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m         response\u001b[39m.\u001b[39mraise_for_status()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/sessions.py:635\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    625\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 635\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    562\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='b4dab246-dddf-4d76-a066-265a3de89d38.westeurope.azurecontainer.io', port=80): Max retries exceeded with url: /score (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4e58ff9190>: Failed to establish a new connection: [Errno -2] Name or service not known'))"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "test_sample = json.dumps({'data': [[0.0,0.0,3.0,25.14,0.0,0.0,8.4583],[0.0,0.0,3.0,25.14,0.0,0.0,8.4583]]})\n",
        "\n",
        "prediction = service.run(test_sample)\n",
        "\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No service with name aciservice-multimodel found to delete.\n"
          ]
        }
      ],
      "source": [
        "service.delete()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy to AKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.compute import AksCompute, ComputeTarget\n",
        "from azureml.core.webservice import Webservice, AksWebservice"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## New environment for monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "environment_monitoring = Environment('inference-env-monitoring')\n",
        "environment_monitoring.docker.base_image = 'mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest'\n",
        "environment_monitoring.python.conda_dependencies = CondaDependencies.create(conda_packages=[\n",
        "    'pip==20.2.4'],\n",
        "    pip_packages=[\n",
        "    'azureml-defaults',\n",
        "    'inference-schema[numpy-support]',\n",
        "    'joblib',\n",
        "    'numpy',\n",
        "    'azureml-monitoring',\n",
        "    'xgboost',\n",
        "    'scikit-learn=={}'.format(sklearn.__version__)\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inference config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Provision the AKS Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InProgress....................................................................\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your AKS cluster\n",
        "aks_name = 'akscluster1' \n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # config:\n",
        "    '''\n",
        "    \"parameters\": {\n",
        "    \"location\": {\n",
        "      \"value\": \"westeurope\"\n",
        "    },\n",
        "    \"workspaceName\": {\n",
        "      \"value\": \"mlops-AML-WS\"\n",
        "    },\n",
        "    \"computeInstanceName\": {\n",
        "      \"value\": \"akscompute1\"\n",
        "    },\n",
        "    \"agentCount\": {\n",
        "      \"value\": 3\n",
        "    },\n",
        "    \"agentVMSize\": {\n",
        "      \"value\": \"Standard_A2_v2\"\n",
        "    },\n",
        "    \"clusterPurpose\": {\n",
        "      \"value\": \"DevTest\"\n",
        "    }\n",
        "  }\n",
        "    '''\n",
        "    # Use the default configuration (can also provide parameters to customize)\n",
        "    prov_config = AksCompute.provisioning_configuration(location=\"westeurope\",agent_count=2,vm_size=\"Standard_A2_v2\",cluster_purpose=\"DevTest\")\n",
        "    \n",
        "    # Create the cluster\n",
        "    aks_target = ComputeTarget.create(workspace = ws, \n",
        "                                    name = aks_name, \n",
        "                                    provisioning_configuration = prov_config)\n",
        "\n",
        "if aks_target.get_status() != \"Succeeded\":\n",
        "    aks_target.wait_for_completion(show_output=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy model on AKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=get_model('titanic-xgb.pkl',aml_workspace=ws,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "inference_config = InferenceConfig(entry_script='../src/scoring/score_monitoring.py', environment=environment_monitoring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10001/206965663.py:4: FutureWarning: azureml.core.model:\n",
            "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
            "please refer to respective documentations \n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoint-sdk-v2 /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
            "For more information on migration, see https://aka.ms/acimoemigration. \n",
            "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
            "  aks_service = Model.deploy(workspace=ws,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-12-21 12:13:15+00:00 Creating Container Registry if not exists.\n",
            "2022-12-21 12:13:15+00:00 Registering the environment.\n",
            "2022-12-21 12:13:16+00:00 Use the existing image.\n",
            "2022-12-21 12:13:18+00:00 Creating resources in AKS.\n",
            "2022-12-21 12:13:19+00:00 Submitting deployment to compute.\n",
            "2022-12-21 12:13:19+00:00 Checking the status of deployment aks-service-1..\n",
            "2022-12-21 12:16:59+00:00 Checking the status of inference endpoint aks-service-1.\n",
            "Succeeded\n",
            "AKS service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n"
          ]
        }
      ],
      "source": [
        "aks_config = AksWebservice.deploy_configuration(collect_model_data=True, enable_app_insights=True)\n",
        "aks_service_name ='aks-service-1'\n",
        "\n",
        "aks_service = Model.deploy(workspace=ws,\n",
        "                           name=aks_service_name,\n",
        "                           models=[model],\n",
        "                           inference_config=inference_config,\n",
        "                           deployment_config=aks_config,\n",
        "                           deployment_target=aks_target,\n",
        "                           overwrite=True)\n",
        "\n",
        "aks_service.wait_for_deployment(show_output = True)\n",
        "print(aks_service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "test_sample = json.dumps({'data':[ [1.0,0.0,1.0,54.0,0.0,0.0,51.8625]]})\n",
        "#,[0.0,0.0,3.0,25.14,0.0,0.0,8.4583],[1.0,0.0,1.0,54.0,0.0,0.0,51.8625] [0.0,0.0,3.0,25.14,0.0,0.0,8.4583]\n",
        "\n",
        "prediction = aks_service.run(test_sample)\n",
        "\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "aks_service.delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "aks_service.delete()\n",
        "aks_target.delete()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
