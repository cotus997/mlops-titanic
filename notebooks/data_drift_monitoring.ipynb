{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve collected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get workspace object\n",
    "ws = Workspace.from_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetValidationError",
     "evalue": "DatasetValidationError:\n\tMessage: Failed to validate the data.\nScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by NotFoundException.\n    Found no resources for the input provided: '[REDACTED]'\n| session_id=5124e1f4-cbf2-42b3-affa-c6acd34c87e5\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to validate the data.\\nScriptExecutionException was caused by StreamAccessException.\\n  StreamAccessException was caused by NotFoundException.\\n    Found no resources for the input provided: '[REDACTED]'\\n| session_id=5124e1f4-cbf2-42b3-affa-c6acd34c87e5\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExecutionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_error_handling.py:65\u001b[0m, in \u001b[0;36m_validate_has_data\u001b[0;34m(dataflow, error_message)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     dataflow\u001b[39m.\u001b[39;49mverify_has_data()\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m (dataprep()\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mdataflow\u001b[39m.\u001b[39mDataflowValidationError,\n\u001b[1;32m     67\u001b[0m         dataprep()\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39merrorhandlers\u001b[39m.\u001b[39mExecutionError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_loggerfactory.py:219\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    220\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/dataflow.py:844\u001b[0m, in \u001b[0;36mDataflow.verify_has_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[39mraise\u001b[39;00m EmptyStepsError()\n\u001b[0;32m--> 844\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49m_to_pyrecords()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m DataflowValidationError(\u001b[39m\"\u001b[39m\u001b[39mThe Dataflow produced no records.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/dataflow.py:768\u001b[0m, in \u001b[0;36mDataflow._to_pyrecords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     intermediate_files \u001b[39m=\u001b[39m _write_preppy_with_fallback(\u001b[39m'\u001b[39;49m\u001b[39mDataflow.to_pyrecords\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mself\u001b[39;49m, span_context\u001b[39m=\u001b[39;49mto_dprep_span_context(span\u001b[39m.\u001b[39;49mget_context()))\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(intermediate_files) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_dataframereader.py:192\u001b[0m, in \u001b[0;36m_write_preppy_with_fallback\u001b[0;34m(activity, dataflow, force_clex, span_context)\u001b[0m\n\u001b[1;32m    183\u001b[0m dataflow_to_execute \u001b[39m=\u001b[39m dataflow\u001b[39m.\u001b[39madd_step(\u001b[39m'\u001b[39m\u001b[39mMicrosoft.DPrep.WritePreppyBlock\u001b[39m\u001b[39m'\u001b[39m, {\n\u001b[1;32m    184\u001b[0m     \u001b[39m'\u001b[39m\u001b[39moutputPath\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[1;32m    185\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mifDestinationExists\u001b[39m\u001b[39m'\u001b[39m: IfDestinationExists\u001b[39m.\u001b[39mREPLACE\n\u001b[1;32m    190\u001b[0m })\n\u001b[0;32m--> 192\u001b[0m _execute_with_fallback(activity, dataflow_to_execute, force_clex\u001b[39m=\u001b[39;49mforce_clex, span_context\u001b[39m=\u001b[39;49mspan_context)\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (intermediate_path \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_SUCCESS\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mexists():\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_dataframereader.py:240\u001b[0m, in \u001b[0;36m_execute_with_fallback\u001b[0;34m(activity, dataflow_to_execute, force_clex, span_context)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     clex_execute()\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_dataframereader.py:218\u001b[0m, in \u001b[0;36m_execute_with_fallback.<locals>.clex_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m activity_data \u001b[39m=\u001b[39m Dataflow\u001b[39m.\u001b[39m_dataflow_to_anonymous_activity_data(dataflow_to_execute)\n\u001b[0;32m--> 218\u001b[0m dataflow_to_execute\u001b[39m.\u001b[39;49m_engine_api\u001b[39m.\u001b[39;49mexecute_anonymous_activity(\n\u001b[1;32m    219\u001b[0m     ExecuteAnonymousActivityMessageArguments(\n\u001b[1;32m    220\u001b[0m         anonymous_activity\u001b[39m=\u001b[39;49mactivity_data,\n\u001b[1;32m    221\u001b[0m         span_context\u001b[39m=\u001b[39;49mspan_context\n\u001b[1;32m    222\u001b[0m     )\n\u001b[1;32m    223\u001b[0m )\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_aml_helper.py:38\u001b[0m, in \u001b[0;36mupdate_aml_env_vars.<locals>.decorator.<locals>.wrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     37\u001b[0m     engine_api_func()\u001b[39m.\u001b[39mupdate_environment_variable(changed)\n\u001b[0;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m send_message_func(op_code, message, cancellation_token)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py:159\u001b[0m, in \u001b[0;36mEngineAPI.execute_anonymous_activity\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39m@update_aml_env_vars\u001b[39m(get_engine_api)\n\u001b[1;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute_anonymous_activity\u001b[39m(\u001b[39mself\u001b[39m, message_args: typedefinitions\u001b[39m.\u001b[39mExecuteAnonymousActivityMessageArguments, cancellation_token: CancellationToken \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_message_channel\u001b[39m.\u001b[39;49msend_message(\u001b[39m'\u001b[39;49m\u001b[39mEngine.ExecuteActivity\u001b[39;49m\u001b[39m'\u001b[39;49m, message_args, cancellation_token)\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/engine.py:291\u001b[0m, in \u001b[0;36mMultiThreadMessageChannel.send_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    290\u001b[0m     cancel_on_error()\n\u001b[0;32m--> 291\u001b[0m     raise_engine_error(response[\u001b[39m'\u001b[39;49m\u001b[39merror\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    292\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/errorhandlers.py:10\u001b[0m, in \u001b[0;36mraise_engine_error\u001b[0;34m(error_response)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mScriptExecution\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m error_code:\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mraise\u001b[39;00m ExecutionError(error_response)\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m error_code:\n",
      "\u001b[0;31mExecutionError\u001b[0m: \nError Code: ScriptExecution.StreamAccess.NotFound\nFailed Step: cd2769d4-7aa6-489c-8ce2-99aaf4e68f68\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by NotFoundException.\n    Found no resources for the input provided: 'https://cotuamlsa.blob.core.windows.net/azureml-blobstore-c2d20a6a-b6c3-4509-b119-72420da93433/modeldata/f90533aa-280d-40b9-9949-a7ba0ee9511f/mlops-RG/mlops-AML-WS/aks-service-1/best_model/default/inputs/2022/12/20/inputs.csv'\n| session_id=5124e1f4-cbf2-42b3-affa-c6acd34c87e5",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatasetValidationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m dstore_paths_predictions \u001b[39m=\u001b[39m [(dstore, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/modeldata/f90533aa-280d-40b9-9949-a7ba0ee9511f/mlops-RG/mlops-AML-WS/aks-service-1/best_model/default/predictions/2022/12/20/predictions.csv\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# specify partition format\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#partition_format = 'weather/{state}/{date:yyyy/MM/dd}/data.parquet'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#dset_X = pd.read_csv(dstore_paths_input)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#dset_y = pd.read_csv(dstore_paths_predictions)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# create the Tabular dataset with 'state' and 'date' as virtual columns \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m dset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mTabular\u001b[39m.\u001b[39;49mfrom_delimited_files(path\u001b[39m=\u001b[39;49mdstore_paths_input)\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#dset_y = Dataset.Tabular.from_csv_files(path=dstore_paths_input, partition_format=partition_format)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# assign the timestamp attribute to a real or virtual column in the dataset\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/data_drift_monitoring.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m dset \u001b[39m=\u001b[39m dset\u001b[39m.\u001b[39mwith_timestamp_columns(\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mwith\u001b[39;00m _LoggerFactory\u001b[39m.\u001b[39mtrack_activity(logger, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions) \u001b[39mas\u001b[39;00m al:\n\u001b[1;32m    131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    133\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(al, \u001b[39m'\u001b[39m\u001b[39mactivity_info\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39merror_code\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_factory.py:366\u001b[0m, in \u001b[0;36mTabularDatasetFactory.from_delimited_files\u001b[0;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format, support_multi_line, empty_as_string, encoding)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     dataflow \u001b[39m=\u001b[39m dataprep()\u001b[39m.\u001b[39mread_csv(path,\n\u001b[1;32m    358\u001b[0m                                    verify_exists\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    359\u001b[0m                                    include_path\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                    quoting\u001b[39m=\u001b[39msupport_multi_line,\n\u001b[1;32m    364\u001b[0m                                    encoding\u001b[39m=\u001b[39mencoding)\n\u001b[0;32m--> 366\u001b[0m dataflow \u001b[39m=\u001b[39m _transform_and_validate(\n\u001b[1;32m    367\u001b[0m     dataflow, partition_format, include_path,\n\u001b[1;32m    368\u001b[0m     validate,\n\u001b[1;32m    369\u001b[0m     infer_column_types \u001b[39mor\u001b[39;49;00m _is_inference_required(set_column_types))\n\u001b[1;32m    370\u001b[0m \u001b[39mif\u001b[39;00m infer_column_types:\n\u001b[1;32m    371\u001b[0m     column_types_builder \u001b[39m=\u001b[39m dataflow\u001b[39m.\u001b[39mbuilders\u001b[39m.\u001b[39mset_column_types()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_factory.py:1173\u001b[0m, in \u001b[0;36m_transform_and_validate\u001b[0;34m(dataflow, partition_format, include_path, validate, infer_column_types)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     dataflow \u001b[39m=\u001b[39m dataflow\u001b[39m.\u001b[39mdrop_columns(\u001b[39m'\u001b[39m\u001b[39mPath\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1172\u001b[0m \u001b[39mif\u001b[39;00m validate:\n\u001b[0;32m-> 1173\u001b[0m     _validate_has_data(dataflow, \u001b[39m'\u001b[39;49m\u001b[39mFailed to validate the data.\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m   1174\u001b[0m \u001b[39melif\u001b[39;00m infer_column_types:\n\u001b[1;32m   1175\u001b[0m     _validate_has_data(dataflow, \u001b[39m'\u001b[39m\u001b[39mFailed to infer column type.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1176\u001b[0m                                  \u001b[39m'\u001b[39m\u001b[39mif data is inaccessible, please set infer_column_types to False.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_error_handling.py:68\u001b[0m, in \u001b[0;36m_validate_has_data\u001b[0;34m(dataflow, error_message)\u001b[0m\n\u001b[1;32m     65\u001b[0m     dataflow\u001b[39m.\u001b[39mverify_has_data()\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m (dataprep()\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mdataflow\u001b[39m.\u001b[39mDataflowValidationError,\n\u001b[1;32m     67\u001b[0m         dataprep()\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39merrorhandlers\u001b[39m.\u001b[39mExecutionError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetValidationError(error_message \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m e\u001b[39m.\u001b[39mcompliant_message, exception\u001b[39m=\u001b[39me)\n",
      "\u001b[0;31mDatasetValidationError\u001b[0m: DatasetValidationError:\n\tMessage: Failed to validate the data.\nScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by NotFoundException.\n    Found no resources for the input provided: '[REDACTED]'\n| session_id=5124e1f4-cbf2-42b3-affa-c6acd34c87e5\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to validate the data.\\nScriptExecutionException was caused by StreamAccessException.\\n  StreamAccessException was caused by NotFoundException.\\n    Found no resources for the input provided: '[REDACTED]'\\n| session_id=5124e1f4-cbf2-42b3-affa-c6acd34c87e5\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# get datastore object \n",
    "dstore = ws.get_default_datastore()\n",
    "# specify datastore paths\n",
    "#/modeldata/<subscriptionid>/<resourcegroup>/<workspace>/<webservice>/<model>/<version>/<designation>/<year>/<month>/<day>/data.csv\n",
    "dstore_paths_input = [(dstore, f'/modeldata/f90533aa-280d-40b9-9949-a7ba0ee9511f/mlops-rg/mlops-aml-ws/aks-service-1/best_model/default/inputs/2022/12/20/inputs.csv')]\n",
    "dstore_paths_predictions = [(dstore, f'/modeldata/f90533aa-280d-40b9-9949-a7ba0ee9511f/mlops-rg/mlops-aml-ws/aks-service-1/best_model/default/predictions/2022/12/20/predictions.csv')]\n",
    "\n",
    "# specify partition format\n",
    "#partition_format = 'weather/{state}/{date:yyyy/MM/dd}/data.parquet'\n",
    "#dset_X = pd.read_csv(dstore_paths_input)\n",
    "#dset_y = pd.read_csv(dstore_paths_predictions)\n",
    "# create the Tabular dataset with 'state' and 'date' as virtual columns \n",
    "dset = Dataset.Tabular.from_delimited_files(path=dstore_paths_input)\n",
    "#dset_y = Dataset.Tabular.from_csv_files(path=dstore_paths_input, partition_format=partition_format)\n",
    "# assign the timestamp attribute to a real or virtual column in the dataset\n",
    "dset = dset.with_timestamp_columns('date')\n",
    "\n",
    "# register the dataset as the target dataset\n",
    "dset = dset.register(ws, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
