{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "gather": {
          "logged": 1670961745732
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.pipeline.core import Pipeline, PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "import os\n",
        "\n",
        "from azureml.core import Workspace,Experiment, Environment\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Defining utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getOrCreateCompute(ws:Workspace):\n",
        "    \n",
        "    from azureml.core.compute import AmlCompute\n",
        "    from azureml.core.compute import ComputeTarget\n",
        "    from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "    aml_compute_target = \"testcot\"\n",
        "    try:\n",
        "        aml_compute = AmlCompute(ws, aml_compute_target)\n",
        "        print(\"found existing compute target.\")\n",
        "    except ComputeTargetException:\n",
        "        print(\"creating new compute target\")\n",
        "\n",
        "        provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
        "                                                                    min_nodes = 0, \n",
        "                                                                    max_nodes = 4)    \n",
        "        aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
        "        aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    finally:\n",
        "        return aml_compute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createRunConfig(ws):\n",
        "    \n",
        "    from azureml.core.runconfig import RunConfiguration\n",
        "    from azure.ai.ml import MLClient\n",
        "    from azure.identity import DefaultAzureCredential\n",
        "    from azureml.core import Environment\n",
        "    # create a new runconfig object\n",
        "    run_config = RunConfiguration()\n",
        "    env = Environment.get(workspace=ws, name='TITANIC', version='1')\n",
        "\n",
        "    run_config.environment=env\n",
        "\n",
        "    \n",
        "\n",
        "    return run_config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build dev pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlops-aml-ws\n",
            "mlops-rg\n",
            "westeurope\n",
            "f90533aa-280d-40b9-9949-a7ba0ee9511f\n",
            "Blobstore's name: workspaceblobstore\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "\n",
        "# Default datastore (Azure blob storage)\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "#def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
        "print(\"Blobstore's name: {}\".format(def_blob_store.name))\n",
        "#Upload file to datastore\n",
        "\n",
        "# Use a CSV to read in the data set.\n",
        "file_name = \"../data/rawdata/train.csv\"\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    raise Exception(\n",
        "        'Could not find CSV dataset at \"%s\". '\n",
        "        % file_name\n",
        "    )  # NOQA: E50\n",
        "# Upload file to default datastore in workspace"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uploading data to blob storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "gather": {
          "logged": 1670961575665
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "found existing compute target.\n"
          ]
        }
      ],
      "source": [
        "target_path = \"training-data/\"\n",
        "def_blob_store.upload_files(\n",
        "    files=[file_name],\n",
        "    target_path=target_path,\n",
        "    overwrite=True,\n",
        "    show_progress=False,\n",
        ")\n",
        "\n",
        "blob_input_data = DataReference(\n",
        "    datastore=def_blob_store,\n",
        "    data_reference_name=\"test_data\",\n",
        "    path_on_datastore=\"training-data/train.csv\")\n",
        "\n",
        "\n",
        "aml_compute = getOrCreateCompute(ws)\n",
        "run_config = createRunConfig(ws)\n",
        "#processed_data1 = PipelineData(\"processed_data1\",datastore=def_blob_store)\n",
        "train_data = PipelineData(\"train_data1\",datastore=def_blob_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "gather": {
          "logged": 1670961575794
        }
      },
      "outputs": [],
      "source": [
        "source_directory=\"../src/preprocess/\"\n",
        "preprocess_step = PythonScriptStep(\n",
        "    script_name=\"preprocess.py\", \n",
        "    arguments=[\"--data\", blob_input_data],\n",
        "    inputs=[blob_input_data],\n",
        "    compute_target=aml_compute, \n",
        "    source_directory=source_directory,\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azureml.pipeline.core.pipeline.Pipeline at 0x7f81a5dccb80>"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.pipeline.core import Pipeline\n",
        "Pipeline(ws, [preprocess_step])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "gather": {
          "logged": 1670961575919
        }
      },
      "outputs": [],
      "source": [
        "source_directory=\"../src/train/\"\n",
        "train_step = PythonScriptStep(\n",
        "    name=\"Train Model\",\n",
        "    script_name=\"train.py\",\n",
        "    compute_target=aml_compute,\n",
        "    source_directory=source_directory,\n",
        "    outputs=[train_data],\n",
        "    arguments=[\n",
        "        \"--model\",\n",
        "        train_data\n",
        "    ],\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=True,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "gather": {
          "logged": 1670961576044
        }
      },
      "outputs": [],
      "source": [
        "source_directory=\"../src/evaluation/\"\n",
        "evaluate_step = PythonScriptStep(\n",
        "    name=\"Evaluate Model \",\n",
        "    script_name=\"eval.py\",\n",
        "    compute_target=aml_compute,\n",
        "    source_directory=source_directory,\n",
        "    inputs=[train_data],\n",
        "    arguments=[\n",
        "        \"--model_path\",\n",
        "        train_data,\n",
        "    ],\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=True,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "gather": {
          "logged": 1670961750727
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import Pipeline\n",
        "train_step.run_after(preprocess_step)\n",
        "evaluate_step.run_after(train_step)\n",
        "steps = [preprocess_step,train_step, evaluate_step]\n",
        "\n",
        "train_pipeline = Pipeline(workspace=ws, steps=steps)\n",
        "#train_pipeline._set_experiment_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "gather": {
          "logged": 1670961582316
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step preprocess.py [b703d092][c2104953-5cc0-4024-aeb5-d193a042ee4c], (This step is eligible to reuse a previous run's output)\n",
            "Created step Train Model [bab87395][003f6e18-1c99-4255-9809-8771dbd67ce5], (This step is eligible to reuse a previous run's output)\n",
            "Created step Evaluate Model  [4210397a][cc8ead9b-6605-4bb0-81e6-30f1fdb35fec], (This step will run and generate new outputs)\n",
            "Using data reference test_data for StepId [91e38c09][ee17b8e7-aad7-4670-a604-b0b5a122ca4f], (Consumers of this data are eligible to reuse prior runs.)\n",
            "Submitted PipelineRun fbec2f23-da58-4a21-a3f9-88adf10b459d\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/fbec2f23-da58-4a21-a3f9-88adf10b459d?wsid=/subscriptions/f90533aa-280d-40b9-9949-a7ba0ee9511f/resourcegroups/mlops-rg/workspaces/mlops-aml-ws&tid=e99647dc-1b08-454a-bf8c-699181b389ab\n"
          ]
        }
      ],
      "source": [
        "pipeline_run1 = Experiment(ws, 'titanic-pipeline').submit(train_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "gather": {
          "logged": 1670961582327
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PipelineRunId: fbec2f23-da58-4a21-a3f9-88adf10b459d\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/fbec2f23-da58-4a21-a3f9-88adf10b459d?wsid=/subscriptions/f90533aa-280d-40b9-9949-a7ba0ee9511f/resourcegroups/mlops-rg/workspaces/mlops-aml-ws&tid=e99647dc-1b08-454a-bf8c-699181b389ab\n",
            "PipelineRun Status: NotStarted\n",
            "PipelineRun Status: Running\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "\n",
            "Warnings:\n",
            "Failed to post metric due to validation failure. Metric column found with a malformed type\n",
            "{'runId': 'fbec2f23-da58-4a21-a3f9-88adf10b459d', 'status': 'Completed', 'startTimeUtc': '2022-12-14T15:59:22.22467Z', 'endTimeUtc': '2022-12-14T16:02:50.156161Z', 'services': {}, 'warnings': [{'source': 'RunHistoryService', 'message': 'Failed to post metric due to validation failure. Metric column found with a malformed type'}], 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2022-12-14T15:59:22.6768937+00:00\",\"EndTime\":\"2022-12-14T16:02:50.0698233+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://cotuamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.fbec2f23-da58-4a21-a3f9-88adf10b459d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=4D5gVqOhBV6VvTyl4Yo7HzBVqGGah%2B%2BQlMvQGCV864s%3D&skoid=75cf7e0a-b2ab-41a4-81a6-c6fc9f4e1474&sktid=e99647dc-1b08-454a-bf8c-699181b389ab&skt=2022-12-14T11%3A24%3A57Z&ske=2022-12-15T19%3A34%3A57Z&sks=b&skv=2019-07-07&st=2022-12-14T15%3A52%3A10Z&se=2022-12-15T00%3A02%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://cotuamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.fbec2f23-da58-4a21-a3f9-88adf10b459d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=nSxripoiWR9nmn5QEzGRQKL8rbX%2FRVWZD29kio4vxIU%3D&skoid=75cf7e0a-b2ab-41a4-81a6-c6fc9f4e1474&sktid=e99647dc-1b08-454a-bf8c-699181b389ab&skt=2022-12-14T11%3A24%3A57Z&ske=2022-12-15T19%3A34%3A57Z&sks=b&skv=2019-07-07&st=2022-12-14T15%3A52%3A10Z&se=2022-12-15T00%3A02%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://cotuamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.fbec2f23-da58-4a21-a3f9-88adf10b459d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=NJyf9Q50pmftaGKpmrY7Ss7V2njh7q43dPxvn099A7w%3D&skoid=75cf7e0a-b2ab-41a4-81a6-c6fc9f4e1474&sktid=e99647dc-1b08-454a-bf8c-699181b389ab&skt=2022-12-14T11%3A24%3A57Z&ske=2022-12-15T19%3A34%3A57Z&sks=b&skv=2019-07-07&st=2022-12-14T15%3A52%3A10Z&se=2022-12-15T00%3A02%3A10Z&sp=r'}, 'submittedBy': 'Giosuè Cotugno'}\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Finished'"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_run1.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "gather": {
          "logged": 1670961582337
        }
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "gather": {
          "logged": 1670961582348
        }
      },
      "outputs": [],
      "source": [
        "# Creating a local endpoint\n",
        "import datetime\n",
        "\n",
        "local_endpoint_name = \"local-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "  name=local_endpoint_name, description=\"this is a sample local endpoint\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.model import Model as AMLModel\n",
        "def get_model(\n",
        "    model_name: str,\n",
        "    model_version: int = None,  # If none, return latest model\n",
        "    tag_name: str = None,\n",
        "    tag_value: str = None,\n",
        "    aml_workspace: Workspace = None\n",
        ") -> AMLModel:\n",
        "    \"\"\"\n",
        "    Retrieves and returns a model from the workspace by its name\n",
        "    and (optional) tag.\n",
        "\n",
        "    Parameters:\n",
        "    aml_workspace (Workspace): aml.core Workspace that the model lives.\n",
        "    model_name (str): name of the model we are looking for\n",
        "    (optional) model_version (str): model version. Latest if not provided.\n",
        "    (optional) tag (str): the tag value & name the model was registered under.\n",
        "\n",
        "    Return:\n",
        "    A single aml model from the workspace that matches the name and tag, or\n",
        "    None.\n",
        "    \"\"\"\n",
        "    if aml_workspace is None:\n",
        "        print(\"No workspace defined - using current experiment workspace.\")\n",
        "        raise ValueError(\n",
        "                \"No workspace provided\"\n",
        "            )\n",
        "\n",
        "    tags = None\n",
        "    if tag_name is not None or tag_value is not None:\n",
        "        # Both a name and value must be specified to use tags.\n",
        "        if tag_name is None or tag_value is None:\n",
        "            raise ValueError(\n",
        "                \"model_tag_name and model_tag_value should both be supplied\"\n",
        "                + \"or excluded\"  # NOQA: E501\n",
        "            )\n",
        "        tags = [[tag_name, tag_value]]\n",
        "\n",
        "    model = None\n",
        "    if model_version is not None:\n",
        "        # TODO(tcare): Finding a specific version currently expects exceptions\n",
        "        # to propagate in the case we can't find the model. This call may\n",
        "        # result in a WebserviceException that may or may not be due to the\n",
        "        # model not existing.\n",
        "        model = AMLModel(\n",
        "            aml_workspace,\n",
        "            name=model_name,\n",
        "            version=model_version,\n",
        "            tags=tags)\n",
        "    else:\n",
        "        models = AMLModel.list(\n",
        "            aml_workspace, name=model_name, tags=tags, latest=True)\n",
        "        if len(models) == 1:\n",
        "            model = models[0]\n",
        "        elif len(models) > 1:\n",
        "            raise Exception(\"Expected only one model\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = Environment(\"env\",\n",
        "    conda_file=\"../src/train/models/trained_model/conda.yaml\",\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"\n",
        ")\n",
        "model = Model(path=\"../src/train/models/trained_model/model.pkl\")\n",
        "\n",
        "ml_client= MLClient.from_config(DefaultAzureCredential())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=get_model(\"titanic-xgb.pkl\",aml_workspace=ws)\n",
        "env = Environment.get(workspace=ws, name='TITANIC', version='3')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model deploying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning, azureml-defaults not detected in provided environment pip dependencies. The azureml-defaults package contains requirements for the inference stack to run, and should be included.\n",
            "/tmp/ipykernel_13312/4040477408.py:11: FutureWarning: azureml.core.model:\n",
            "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
            "please refer to respective documentations \n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoint-sdk-v2 /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
            "For more information on migration, see https://aka.ms/acimoemigration. \n",
            "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
            "  service = Model.deploy(workspace=ws,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-12-14 19:10:38+00:00 Creating Container Registry if not exists.\n",
            "2022-12-14 19:10:38+00:00 Registering the environment.\n",
            "2022-12-14 19:10:39+00:00 Use the existing image.\n",
            "2022-12-14 19:10:39+00:00 Generating deployment configuration.\n",
            "2022-12-14 19:10:41+00:00 Submitting deployment to compute.\n",
            "2022-12-14 19:10:44+00:00 Checking the status of deployment my-custom-env-service..\n",
            "2022-12-14 19:38:14+00:00 Checking the status of inference endpoint my-custom-env-service.\n",
            "Failed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
            "Operation ID: 605f8e37-8720-40b8-93b3-2da521e9c57b\n",
            "More information can be found using '.get_logs()'\n",
            "Error:\n",
            "{\n",
            "  \"code\": \"AciDeploymentFailed\",\n",
            "  \"statusCode\": 400,\n",
            "  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
            "\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
            "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n",
            "  \"details\": [\n",
            "    {\n",
            "      \"code\": \"CrashLoopBackOff\",\n",
            "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
            "\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
            "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
            "    },\n",
            "    {\n",
            "      \"code\": \"AciDeploymentFailed\",\n",
            "      \"message\": \"Your container application crashed. Please follow the steps to debug:\n",
            "\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n",
            "\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n",
            "\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
            "\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n",
            "\"RestartCount\": 3\n",
            "\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n",
            "\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-12-14T19:38:54.679Z\",\"exitCode\":111,\"finishTime\":\"2022-12-14T19:38:09.66Z\",\"detailStatus\":\"Error\"}\n",
            "\"Events\":\n",
            "{\"count\":3,\"firstTimestamp\":\"2022-12-14T18:38:53Z\",\"lastTimestamp\":\"2022-12-14T19:37:11Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\"\",\"type\":\"Normal\"}\n",
            "{\"count\":3,\"firstTimestamp\":\"2022-12-14T18:41:03Z\",\"lastTimestamp\":\"2022-12-14T19:37:12Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\"\",\"type\":\"Normal\"}\n",
            "{\"count\":20,\"firstTimestamp\":\"2022-12-14T18:42:30Z\",\"lastTimestamp\":\"2022-12-14T19:38:01Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n",
            "{\"count\":23,\"firstTimestamp\":\"2022-12-14T18:42:37Z\",\"lastTimestamp\":\"2022-12-14T19:38:54Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 824b01015307ccfd71dcb3765f7f6b24bdcc4c7005618bca9b59ef7ff28fb5e3.\",\"type\":\"Normal\"}\n",
            "{\"count\":2,\"firstTimestamp\":\"2022-12-14T19:38:32Z\",\"lastTimestamp\":\"2022-12-14T19:38:54Z\",\"name\":\"BackOff\",\"message\":\"Back-off restarting failed container\",\"type\":\"Warning\"}\n",
            "\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 605f8e37-8720-40b8-93b3-2da521e9c57b\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-12-14T19:38:54.679Z\",\"exitCode\":111,\"finishTime\":\"2022-12-14T19:38:09.66Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":3,\"firstTimestamp\":\"2022-12-14T18:38:53Z\",\"lastTimestamp\":\"2022-12-14T19:37:11Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\"\",\"type\":\"Normal\"}\n{\"count\":3,\"firstTimestamp\":\"2022-12-14T18:41:03Z\",\"lastTimestamp\":\"2022-12-14T19:37:12Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\"\",\"type\":\"Normal\"}\n{\"count\":20,\"firstTimestamp\":\"2022-12-14T18:42:30Z\",\"lastTimestamp\":\"2022-12-14T19:38:01Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":23,\"firstTimestamp\":\"2022-12-14T18:42:37Z\",\"lastTimestamp\":\"2022-12-14T19:38:54Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 824b01015307ccfd71dcb3765f7f6b24bdcc4c7005618bca9b59ef7ff28fb5e3.\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2022-12-14T19:38:32Z\",\"lastTimestamp\":\"2022-12-14T19:38:54Z\",\"name\":\"BackOff\",\"message\":\"Back-off restarting failed container\",\"type\":\"Warning\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 605f8e37-8720-40b8-93b3-2da521e9c57b\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2022-12-14T19:38:54.679Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2022-12-14T19:38:09.66Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":3,\\\"firstTimestamp\\\":\\\"2022-12-14T18:38:53Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:37:11Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":3,\\\"firstTimestamp\\\":\\\"2022-12-14T18:41:03Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:37:12Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":20,\\\"firstTimestamp\\\":\\\"2022-12-14T18:42:30Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:38:01Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":23,\\\"firstTimestamp\\\":\\\"2022-12-14T18:42:37Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:38:54Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 824b01015307ccfd71dcb3765f7f6b24bdcc4c7005618bca9b59ef7ff28fb5e3.\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2022-12-14T19:38:32Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:38:54Z\\\",\\\"name\\\":\\\"BackOff\\\",\\\"message\\\":\\\"Back-off restarting failed container\\\",\\\"type\\\":\\\"Warning\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m aci_config \u001b[39m=\u001b[39m AciWebservice\u001b[39m.\u001b[39mdeploy_configuration(cpu_cores\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, memory_gb\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m service \u001b[39m=\u001b[39m Model\u001b[39m.\u001b[39mdeploy(workspace\u001b[39m=\u001b[39mws,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                        name\u001b[39m=\u001b[39mservice_name,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m                        models\u001b[39m=\u001b[39m[model],\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m                        inference_config\u001b[39m=\u001b[39minference_config,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m                        deployment_config\u001b[39m=\u001b[39maci_config,\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m                        overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66393035333361612d323830642d343062392d393934392d6137626130656539353131662f7265736f7572636547726f7570732f6d6c6f70732d52472f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c6f70732d414d4c2d57532f636f6d70757465732f74657374636f7475/home/azureuser/cloudfiles/code/Users/giosue.cotugno/mlops_titanic/notebooks/mlops-ci.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m service\u001b[39m.\u001b[39;49mwait_for_deployment(show_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/webservice.py:918\u001b[0m, in \u001b[0;36mWebservice.wait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m logs_response:\n\u001b[1;32m    916\u001b[0m             logs_response \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCurrent sub-operation type not known, more logs unavailable.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 918\u001b[0m         \u001b[39mraise\u001b[39;00m WebserviceException(\u001b[39m'\u001b[39m\u001b[39mService deployment polling reached non-successful terminal state, current \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    919\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mservice state: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    920\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mOperation ID: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    921\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    922\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39mError:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    923\u001b[0m                                   \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operation_endpoint\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    924\u001b[0m                                               logs_response, format_error_response), logger\u001b[39m=\u001b[39mmodule_logger)\n\u001b[1;32m    925\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m service creation operation finished, operation \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_webservice_type,\n\u001b[1;32m    926\u001b[0m                                                                           operation_state))\n\u001b[1;32m    927\u001b[0m \u001b[39mexcept\u001b[39;00m WebserviceException \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 605f8e37-8720-40b8-93b3-2da521e9c57b\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-12-14T19:38:54.679Z\",\"exitCode\":111,\"finishTime\":\"2022-12-14T19:38:09.66Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":3,\"firstTimestamp\":\"2022-12-14T18:38:53Z\",\"lastTimestamp\":\"2022-12-14T19:37:11Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\"\",\"type\":\"Normal\"}\n{\"count\":3,\"firstTimestamp\":\"2022-12-14T18:41:03Z\",\"lastTimestamp\":\"2022-12-14T19:37:12Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\"\",\"type\":\"Normal\"}\n{\"count\":20,\"firstTimestamp\":\"2022-12-14T18:42:30Z\",\"lastTimestamp\":\"2022-12-14T19:38:01Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":23,\"firstTimestamp\":\"2022-12-14T18:42:37Z\",\"lastTimestamp\":\"2022-12-14T19:38:54Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 824b01015307ccfd71dcb3765f7f6b24bdcc4c7005618bca9b59ef7ff28fb5e3.\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2022-12-14T19:38:32Z\",\"lastTimestamp\":\"2022-12-14T19:38:54Z\",\"name\":\"BackOff\",\"message\":\"Back-off restarting failed container\",\"type\":\"Warning\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 605f8e37-8720-40b8-93b3-2da521e9c57b\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: my-custom-env-service. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image cotuamlcr.azurecr.io/azureml/azureml_3e60105f08daa192671f86fabaccb6ad locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2022-12-14T19:38:54.679Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2022-12-14T19:38:09.66Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":3,\\\"firstTimestamp\\\":\\\"2022-12-14T18:38:53Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:37:11Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":3,\\\"firstTimestamp\\\":\\\"2022-12-14T18:41:03Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:37:12Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"cotuamlcr.azurecr.io/azureml/azureml_1e46bdebb2cabee349703cdcadaed23c@sha256:62f31832309abe88a7f218664894e2ec94b98fda8a40e57b264feb8466fcd910\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":20,\\\"firstTimestamp\\\":\\\"2022-12-14T18:42:30Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:38:01Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":23,\\\"firstTimestamp\\\":\\\"2022-12-14T18:42:37Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:38:54Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 824b01015307ccfd71dcb3765f7f6b24bdcc4c7005618bca9b59ef7ff28fb5e3.\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2022-12-14T19:38:32Z\\\",\\\"lastTimestamp\\\":\\\"2022-12-14T19:38:54Z\\\",\\\"name\\\":\\\"BackOff\\\",\\\"message\\\":\\\"Back-off restarting failed container\\\",\\\"type\\\":\\\"Warning\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core import Model\n",
        "\n",
        "\n",
        "service_name = 'my-custom-env-service'\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='../src/scoring/score.py', environment=env)\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name=service_name,\n",
        "                       models=[model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "service.wait_for_deployment(show_output=True).get_logs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy\n",
        "\n",
        "input_sample = numpy.array([\n",
        "    [3,'male',22.0,1,0,7.25,'S'],\n",
        "    [1,'female',38.0,1,0,71.2833,'C']])\n",
        "input_payload = json.dumps({\n",
        "    'data': input_sample,\n",
        "    'method': 'predict'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
        "})\n",
        "\n",
        "output = service.run(input_payload)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
