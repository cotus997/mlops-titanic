{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "already moved\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "    os.chdir('Users/giosue.cotugno/mlops_titanic/notebooks/')\n",
        "except:\n",
        "    print('already moved')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "gather": {
          "logged": 1670961745732
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.pipeline.core import Pipeline, PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "import os\n",
        "from azureml.core import Workspace,Experiment, Environment\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Defining utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getOrCreateCompute(ws:Workspace):\n",
        "    \n",
        "    \n",
        "\n",
        "    aml_compute_target = \"testcot\"\n",
        "    try:\n",
        "        aml_compute = AmlCompute(ws, aml_compute_target)\n",
        "        print(\"found existing compute target.\")\n",
        "    except ComputeTargetException:\n",
        "        print(\"creating new compute target\")\n",
        "\n",
        "        provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
        "                                                                    min_nodes = 0, \n",
        "                                                                    max_nodes = 4)    \n",
        "        aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
        "        aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    finally:\n",
        "        return aml_compute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createRunConfig(ws):\n",
        "    \n",
        "    from azureml.core.runconfig import RunConfiguration\n",
        "    from azure.ai.ml import MLClient\n",
        "    from azure.identity import DefaultAzureCredential\n",
        "    from azureml.core import Environment\n",
        "    # create a new runconfig object\n",
        "    run_config = RunConfiguration()\n",
        "    env = Environment.get(workspace=ws, name='TITANIC', version='1')\n",
        "\n",
        "    run_config.environment=env\n",
        "\n",
        "    \n",
        "\n",
        "    return run_config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build dev pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlops-aml-ws\n",
            "mlops-rg\n",
            "westeurope\n",
            "f90533aa-280d-40b9-9949-a7ba0ee9511f\n",
            "Blobstore's name: workspaceblobstore\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "\n",
        "# Default datastore (Azure blob storage)\n",
        "def_blob_store = ws.get_default_datastore()\n",
        "#def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
        "print(\"Blobstore's name: {}\".format(def_blob_store.name))\n",
        "#Upload file to datastore\n",
        "\n",
        "# Use a CSV to read in the data set.\n",
        "file_name = \"../data/rawdata/train.csv\"\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    raise Exception(\n",
        "        'Could not find CSV dataset at \"%s\". '\n",
        "        % file_name\n",
        "    )  # NOQA: E50\n",
        "# Upload file to default datastore in workspace"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uploading data to blob storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "gather": {
          "logged": 1670961575665
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "found existing compute target.\n"
          ]
        }
      ],
      "source": [
        "target_path = \"training-data/\"\n",
        "def_blob_store.upload_files(\n",
        "    files=[file_name],\n",
        "    target_path=target_path,\n",
        "    overwrite=True,\n",
        "    show_progress=False,\n",
        ")\n",
        "\n",
        "blob_input_data = DataReference(\n",
        "    datastore=def_blob_store,\n",
        "    data_reference_name=\"test_data\",\n",
        "    path_on_datastore=\"training-data/train.csv\")\n",
        "\n",
        "\n",
        "aml_compute = getOrCreateCompute(ws)\n",
        "run_config = createRunConfig(ws)\n",
        "#processed_data1 = PipelineData(\"processed_data1\",datastore=def_blob_store)\n",
        "models_data = PipelineData(\"models_data\",datastore=def_blob_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "gather": {
          "logged": 1670961575794
        }
      },
      "outputs": [],
      "source": [
        "source_directory=\"../src/preprocess/\"\n",
        "preprocess_step = PythonScriptStep(\n",
        "    \n",
        "    name=\"Preprocessing Step\",\n",
        "    script_name=\"preprocess.py\", \n",
        "    arguments=[\"--data\", blob_input_data],\n",
        "    inputs=[blob_input_data],\n",
        "    compute_target=aml_compute, \n",
        "    source_directory=source_directory,\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azureml.pipeline.core.pipeline.Pipeline at 0x7f473a040160>"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.pipeline.core import Pipeline\n",
        "Pipeline(ws, [preprocess_step])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "gather": {
          "logged": 1670961575919
        }
      },
      "outputs": [],
      "source": [
        "source_directory=\"../src/train/\"\n",
        "train_step = PythonScriptStep(\n",
        "    name=\"Train Model Step\",\n",
        "    script_name=\"train.py\",\n",
        "    compute_target=aml_compute,\n",
        "    source_directory=source_directory,\n",
        "    outputs=[models_data],\n",
        "    arguments=[\n",
        "        \"--model\",\n",
        "        models_data\n",
        "    ],\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=True,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "gather": {
          "logged": 1670961576044
        }
      },
      "outputs": [],
      "source": [
        "source_directory=\"../src/evaluation/\"\n",
        "evaluate_step = PythonScriptStep(\n",
        "    name=\"Evaluate Model Step\",\n",
        "    script_name=\"eval.py\",\n",
        "    compute_target=aml_compute,\n",
        "    source_directory=source_directory,\n",
        "    inputs=[models_data],\n",
        "    arguments=[\n",
        "        \"--model_path\",\n",
        "        models_data,\n",
        "    ],\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=True,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Registration step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "source_directory=\"../src/register/\"\n",
        "register_step = PythonScriptStep(\n",
        "    name=\"Registration Model Step\",\n",
        "    script_name=\"register.py\",\n",
        "    compute_target=aml_compute,\n",
        "    source_directory=source_directory,\n",
        "    inputs=[models_data],\n",
        "    arguments=[\n",
        "        \"--model_path\",\n",
        "        models_data,\n",
        "    ],\n",
        "    runconfig=run_config,\n",
        "    allow_reuse=False,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "gather": {
          "logged": 1670961750727
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import Pipeline\n",
        "train_step.run_after(preprocess_step)\n",
        "evaluate_step.run_after(train_step)\n",
        "register_step.run_after(evaluate_step)\n",
        "steps = [preprocess_step,train_step, evaluate_step,register_step]\n",
        "\n",
        "train_pipeline = Pipeline(workspace=ws, steps=steps)\n",
        "#train_pipeline._set_experiment_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step Evaluate Model Step is ready to be created [7726e3da]\n",
            "Step Registration Model Step is ready to be created [a984e0d1]\n",
            "Created step Preprocessing Step [aaef40e6][a499580b-0362-4649-9672-de20520987dc], (This step is eligible to reuse a previous run's output)\n",
            "Created step Train Model Step [47e6535f][495e622c-4469-4b8d-b0f0-0d5209d34274], (This step is eligible to reuse a previous run's output)\n",
            "Created step Evaluate Model Step [7726e3da][fcde025d-b63a-4e98-9f55-79314e367eec], (This step will run and generate new outputs)\n",
            "Created step Registration Model Step [a984e0d1][50484aed-f455-4a32-8ff3-0abb133bf6bc], (This step will run and generate new outputs)\n",
            "Using data reference test_data for StepId [5006b6bb][ee17b8e7-aad7-4670-a604-b0b5a122ca4f], (Consumers of this data are eligible to reuse prior runs.)\n",
            "Published pipeline: preproc-train-register pipeline\n"
          ]
        }
      ],
      "source": [
        "train_pipeline.validate()\n",
        "published_pipeline = train_pipeline.publish(\n",
        "    name=\"preproc-train-register pipeline\",\n",
        "    description=\"Model training/retraining pipeline\"\n",
        ")\n",
        "print(f\"Published pipeline: {published_pipeline.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "gather": {
          "logged": 1670961582316
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submitted PipelineRun 969b34c2-d1bd-49c5-9ee5-33764d38ffcc\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/969b34c2-d1bd-49c5-9ee5-33764d38ffcc?wsid=/subscriptions/f90533aa-280d-40b9-9949-a7ba0ee9511f/resourcegroups/mlops-rg/workspaces/mlops-aml-ws&tid=e99647dc-1b08-454a-bf8c-699181b389ab\n"
          ]
        }
      ],
      "source": [
        "pipeline_run1 = Experiment(ws, 'titanic-pipeline').submit(train_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "gather": {
          "logged": 1671188685176
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PipelineRunId: 969b34c2-d1bd-49c5-9ee5-33764d38ffcc\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/969b34c2-d1bd-49c5-9ee5-33764d38ffcc?wsid=/subscriptions/f90533aa-280d-40b9-9949-a7ba0ee9511f/resourcegroups/mlops-rg/workspaces/mlops-aml-ws&tid=e99647dc-1b08-454a-bf8c-699181b389ab\n",
            "PipelineRun Status: Running\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "\n",
            "Warnings:\n",
            "Failed to post metric due to validation failure. Metric column found with a malformed type\n",
            "{'runId': '969b34c2-d1bd-49c5-9ee5-33764d38ffcc', 'status': 'Completed', 'startTimeUtc': '2023-01-05T17:40:45.322379Z', 'endTimeUtc': '2023-01-05T17:47:38.032246Z', 'services': {}, 'warnings': [{'source': 'RunHistoryService', 'message': 'Failed to post metric due to validation failure. Metric column found with a malformed type'}], 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-01-05T17:40:46.0102052+00:00\",\"EndTime\":\"2023-01-05T17:47:37.960073+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://cotuamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.969b34c2-d1bd-49c5-9ee5-33764d38ffcc/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=0yu7oEGl3AFjMnAirDne6jOlZjgd2FVpfXwf2C81Hxw%3D&skoid=75cf7e0a-b2ab-41a4-81a6-c6fc9f4e1474&sktid=e99647dc-1b08-454a-bf8c-699181b389ab&skt=2023-01-05T17%3A13%3A04Z&ske=2023-01-07T01%3A23%3A04Z&sks=b&skv=2019-07-07&st=2023-01-05T17%3A37%3A25Z&se=2023-01-06T01%3A47%3A25Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://cotuamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.969b34c2-d1bd-49c5-9ee5-33764d38ffcc/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=6ADi2wdF4luoxKyrgw69Pg9OizVJ1%2FkmO6MR%2F84wCiA%3D&skoid=75cf7e0a-b2ab-41a4-81a6-c6fc9f4e1474&sktid=e99647dc-1b08-454a-bf8c-699181b389ab&skt=2023-01-05T17%3A13%3A04Z&ske=2023-01-07T01%3A23%3A04Z&sks=b&skv=2019-07-07&st=2023-01-05T17%3A37%3A25Z&se=2023-01-06T01%3A47%3A25Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://cotuamlsa.blob.core.windows.net/azureml/ExperimentRun/dcid.969b34c2-d1bd-49c5-9ee5-33764d38ffcc/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=ZMr3BiWhsW7UsaEtPrP%2BRfSLLY0c%2BmiDTdbGqABsFdc%3D&skoid=75cf7e0a-b2ab-41a4-81a6-c6fc9f4e1474&sktid=e99647dc-1b08-454a-bf8c-699181b389ab&skt=2023-01-05T17%3A13%3A04Z&ske=2023-01-07T01%3A23%3A04Z&sks=b&skv=2019-07-07&st=2023-01-05T17%3A37%3A25Z&se=2023-01-06T01%3A47%3A25Z&sp=r'}, 'submittedBy': 'Giosuè Cotugno'}\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Finished'"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_run1.wait_for_completion(show_output=True)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "68cd809ea8153bc6204cc41955edea3b139b9aa4275a334cb56f84dd9247969a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
